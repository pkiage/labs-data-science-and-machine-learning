{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 700)\n",
    "pd.set_option('display.max_columns', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('../data/external/sales_train.csv.gz')\n",
    "shops = pd.read_csv('../data/external/shops.csv')\n",
    "items = pd.read_csv('../data/external/items.csv')\n",
    "item_cats = pd.read_csv('../data/external/item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[sales['shop_id'].isin([26, 27, 28])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day': 'sum'}).rename(columns = {'item_cnt_day':'target'})\n",
    "# Join it to the grid\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day': 'sum'}).rename(columns = {'item_cnt_day':'target_shop'})\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day': 'sum'}).rename(columns = {'item_cnt_day':'target_item'})\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols)) \n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "for month_shift in shift_range:\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "del train_shift\n",
    "\n",
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12] \n",
    "\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "# Category for each item\n",
    "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test `date_block_num` is 33\n"
     ]
    }
   ],
   "source": [
    "# Save `date_block_num`, as we can't use them as features, but will need them to split the dataset into parts \n",
    "dates = all_data['date_block_num']\n",
    "\n",
    "last_block = dates.max()\n",
    "print(f'Test `date_block_num` is {last_block}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train = dates[dates <  last_block]\n",
    "dates_test  = dates[dates == last_block]\n",
    "\n",
    "X_train = all_data.loc[dates <  last_block].drop(to_drop_cols, axis=1)\n",
    "X_test =  all_data.loc[dates == last_block].drop(to_drop_cols, axis=1)\n",
    "\n",
    "y_train = all_data.loc[dates <  last_block, 'target'].values\n",
    "y_test =  all_data.loc[dates == last_block, 'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32]\n",
      "[33]\n"
     ]
    }
   ],
   "source": [
    "print(dates_train.unique())\n",
    "print(dates_test.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Level Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for linreg is 0.7431801600435046\n"
     ]
    }
   ],
   "source": [
    "# Run linear regression on numeric columns and \n",
    "# get predictions for the last month\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train.values, y_train)\n",
    "pred_lr = lr.predict(X_test.values)\n",
    "\n",
    "print(f'Test R-squared for linreg is {r2_score(y_test, pred_lr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for LightGBM is 0.7312494774665426\n"
     ]
    }
   ],
   "source": [
    "## Run LightGBM\n",
    "\n",
    "lgb_params = {\n",
    "               'feature_fraction': 0.75,\n",
    "               'metric': 'rmse',\n",
    "               'nthread':1, \n",
    "               'min_data_in_leaf': 2**7, \n",
    "               'bagging_fraction': 0.75, \n",
    "               'learning_rate': 0.03, \n",
    "               'objective': 'mse', \n",
    "               'bagging_seed': 2**7, \n",
    "               'num_leaves': 2**7,\n",
    "               'bagging_freq':1,\n",
    "               'verbose':0,\n",
    "               'force_row_wise':True\n",
    "              }\n",
    "\n",
    "model = lgb.train(lgb_params, lgb.Dataset(X_train, label=y_train), 100)\n",
    "pred_lgb = model.predict(X_test)\n",
    "\n",
    "print(f'Test R-squared for LightGBM is {r2_score(y_test, pred_lgb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenate test predictions to get test meta-features\n",
    "X_test_level2 = np.c_[pred_lr, pred_lgb] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train meta-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_train_level2 = dates_train[dates_train.isin([27, 28, 29, 30, 31, 32])]\n",
    "\n",
    "# That is how we get target for the 2nd level dataset\n",
    "y_train_level2 = y_train[dates_train.isin([27, 28, 29, 30, 31, 32])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_train_level2: (34404,)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of y_train_level2: {y_train_level2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27:  X_train_block.shape=(120192, 21),  X_test_block.shape=(6438, 21),   Total Size=126630\n",
      "28:  X_train_block.shape=(126630, 21),  X_test_block.shape=(6804, 21),   Total Size=133434\n",
      "29:  X_train_block.shape=(133434, 21),  X_test_block.shape=(6693, 21),   Total Size=140127\n",
      "30:  X_train_block.shape=(140127, 21),  X_test_block.shape=(6474, 21),   Total Size=146601\n",
      "31:  X_train_block.shape=(146601, 21),  X_test_block.shape=(3618, 21),   Total Size=150219\n",
      "32:  X_train_block.shape=(150219, 21),  X_test_block.shape=(4377, 21),   Total Size=154596\n"
     ]
    }
   ],
   "source": [
    "# And here we create 2nd level feeature matrix, init it with zeros first\n",
    "X_train_level2 = np.zeros([y_train_level2.shape[0], 2])\n",
    "\n",
    "# Now fill `X_train_level2` with metafeatures\n",
    "for cur_block_num in [27, 28, 29, 30, 31, 32]:\n",
    "    \n",
    "    print(cur_block_num, end='')\n",
    "    \n",
    "    '''\n",
    "        1. Split `X_train` into parts\n",
    "           Remember, that corresponding dates are stored in `dates_train` \n",
    "        2. Fit linear regression \n",
    "        3. Fit LightGBM and put predictions          \n",
    "        4. Store predictions from 2. and 3. in the right place of `X_train_level2`. \n",
    "           You can use `dates_train_level2` for it\n",
    "           Make sure the order of the meta-features is the same as in `X_test_level2`\n",
    "    '''      \n",
    "    \n",
    "    X_train_block = all_data.loc[dates < cur_block_num].drop(to_drop_cols, axis=1)\n",
    "    X_test_block = all_data.loc[dates == cur_block_num].drop(to_drop_cols, axis=1)\n",
    "    \n",
    "    y_train_block = all_data.loc[dates <  cur_block_num, 'target'].values\n",
    "    y_test_block = all_data.loc[dates == cur_block_num, 'target'].values\n",
    "    \n",
    "    print(':  X_train_block.shape={}'.format(X_train_block.shape), end='')\n",
    "    print(',  X_test_block.shape={}'.format(X_test_block.shape), end='')\n",
    "    print(',   Total Size={}'.format(X_train_block.shape[0] + X_test_block.shape[0]), end='')\n",
    "    print()\n",
    "    \n",
    "    lr.fit(X_train_block.values, y_train_block)\n",
    "    X_train_level2[dates_train_level2 == cur_block_num, 0] = lr.predict(X_test_block.values)\n",
    "    \n",
    "    model = lgb.train(lgb_params, lgb.Dataset(X_train_block, label=y_train_block), 100)\n",
    "    X_train_level2[dates_train_level2 == cur_block_num, 1] = model.predict(X_test_block) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1e8d111f850>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train_level2[:, 0], X_train_level2[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n",
    "\n",
    "When the meta-features are created, we can ensemble our first level models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Convex Mix\n",
    "\n",
    "We need to find an optimal $\\alpha$. And it is very easy, as it is feasible to do grid search. Next, find the optimal $\\alpha$ out of `alphas_to_try` array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.762; Corresponding r2 score on train: 0.6271958302095351\n"
     ]
    }
   ],
   "source": [
    "alphas_to_try = np.linspace(0, 1, 1001)\n",
    "\n",
    "r2_scores = np.array([r2_score(y_train_level2, np.dot(X_train_level2, [alpha, 1 - alpha])) for alpha in alphas_to_try])\n",
    "best_alpha = alphas_to_try[r2_scores.argmax()] \n",
    "r2_train_simple_mix = r2_scores.max() \n",
    "\n",
    "print(f'Best alpha: {best_alpha}; Corresponding r2 score on train: {r2_train_simple_mix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the $\\alpha$ you've found to compute predictions for the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R-squared for simple mix is 0.7812102964363891\n"
     ]
    }
   ],
   "source": [
    "test_preds = best_alpha * pred_lr + (1 - best_alpha) * pred_lgb \n",
    "r2_test_simple_mix = r2_score(y_test, test_preds)\n",
    "\n",
    "print(f'Test R-squared for simple mix is {r2_test_simple_mix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "A more advanced ensembling technique. Fit a linear regression model to the meta-features. Use the same parameters as in the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:            [0.80668174 0.09546006]\n",
      "Normalized Coefficient: [0.89418508 0.10581492]\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_level2, y_train_level2)\n",
    "\n",
    "print(f'Coefficient:            {lr.coef_}')\n",
    "print(f'Normalized Coefficient: {lr.coef_ / lr.coef_.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R-squared for stacking is 0.632092200807368\n",
      "Test  R-squared for stacking is 0.771341806729652\n"
     ]
    }
   ],
   "source": [
    "train_preds = lr.predict(X_train_level2) \n",
    "r2_train_stacking = r2_score(y_train_level2, train_preds) \n",
    "\n",
    "test_preds = lr.predict(np.vstack((pred_lr, pred_lgb)).T) \n",
    "r2_test_stacking = r2_score(y_test, test_preds) \n",
    "\n",
    "print(f'Train R-squared for stacking is {r2_train_stacking}')\n",
    "print(f'Test  R-squared for stacking is {r2_test_stacking}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
